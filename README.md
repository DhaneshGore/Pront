# ğŸ“ Prompt Analysis & Enhancement System

## ğŸ“Œ Project Overview
This project provides an **advanced system for analyzing and enhancing prompts** using **Google Gemini API** and **Hugging Face API**. It helps improve prompt clarity, completeness, and specificity while selecting the best LLM for the task.

## ğŸš€ Features
- **Prompt Analysis:** Identifies missing elements, clarity score, and context completeness.
- **LLM Selection:** Recommends either **Google Gemini** or **Hugging Face** based on prompt complexity.
- **Prompt Enhancement:** Improves the given prompt using **prompt engineering techniques**.
- **Structured JSON Output:** Generates an output with enhanced prompts and improvement metrics.
- **Streamlit UI:** User-friendly interface for easy input and results display.

## ğŸ“‚ Project Structure
```
ğŸ“‚ Prompt-Enhancer/
â”‚â”€â”€ ğŸ“„ app.py                      # Streamlit app (Main entry point)
â”‚â”€â”€ ğŸ“‚ config/                     # Configuration files
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py              # Marks the directory as a package
â”‚   â”œâ”€â”€ ğŸ“„ settings.py              # Configuration settings
â”‚â”€â”€ ğŸ“‚ utils/                       # Utility functions
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py              # Marks the directory as a package
â”‚   â”œâ”€â”€ ğŸ“„ analysis.py              # Prompt analysis functions
â”‚   â”œâ”€â”€ ğŸ“„ enhancement.py           # Prompt enhancement functions
â”‚   â”œâ”€â”€ ğŸ“„ llm_selection.py         # LLM selection logic
â”‚â”€â”€ ğŸ“‚ models/                      # LLM API integrations
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py              # Marks the directory as a package
â”‚   â”œâ”€â”€ ğŸ“„ gemini_api.py            # Google Gemini API wrapper
â”‚   â”œâ”€â”€ ğŸ“„ huggingface_api.py       # Hugging Face API wrapper
â”‚â”€â”€ ğŸ“‚ tests/                       # Unit tests
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py              # Marks the directory as a package
â”‚   â”œâ”€â”€ ğŸ“„ test_analysis.py         # Tests for analysis module
â”‚   â”œâ”€â”€ ğŸ“„ test_enhancement.py      # Tests for enhancement module
â”‚â”€â”€ ğŸ“‚ venv/                        # Virtual environment (ignore in Git)
â”‚â”€â”€ ğŸ“„ requirements.txt             # Python dependencies
â”‚â”€â”€ ğŸ“„ README.md                    # Project documentation
â”‚â”€â”€ ğŸ“„ .gitignore                   # Ignore unnecessary files
```

## ğŸ”§ Installation
### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/DhaneshGore/Prompt-Analysis-Enhancement-System.git
cd Prompt-Enhancer
```

### 2ï¸âƒ£ Set Up a Virtual Environment (Recommended)
```bash
conda create --name prompt_env python=3.9
conda activate prompt_env
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

## â–¶ï¸ Running the Streamlit App
Start the Streamlit web application:
```bash
streamlit run app.py
```
This will open the app in your **browser**.

## ğŸ§ª Running Tests
Run unit tests to verify that everything is working correctly:
```bash
python -m unittest discover tests
```

## ğŸ“œ Example Input/Output
### **Example Input:**
```json
{
    "prompt": "write code for sorting array"
}
```

### **Expected Output:**
```json
{
    "analysis": {
        "missing_elements": ["array type", "sorting order", "performance requirements"],
        "context_score": 0.4,
        "clarity_score": 0.5
    },
    "recommended_llm": {
        "model": "Google Gemini",
        "reasoning": "Technical task requiring code generation and understanding of implementation details"
    },
    "enhanced_prompt": {
        "text": "Write a Python function to sort an array of integers in ascending order. Include time complexity analysis and handle edge cases like empty arrays.",
        "technique": "Specification Expansion",
        "improvement_metrics": {
            "clarity": +0.4,
            "context": +0.5,
            "specificity": +0.6
        }
    }
}
```

## ğŸš€ Deploying with Docker
### 1ï¸âƒ£ Build the Docker Image
```bash
docker build -t your-dockerhub-username/prompt-analyzer .
```

### 2ï¸âƒ£ Run the Docker Container Locally
```bash
docker run -p 8501:8501 your-dockerhub-username/prompt-analyzer
```

### 3ï¸âƒ£ Push the Image to Docker Hub
```bash
docker login
docker push your-dockerhub-username/prompt-analyzer
```

## ğŸ› ï¸ Future Enhancements
- Add support for more LLMs like **Anthropic Claude** and **Cohere**.
- Implement **logging & error handling** for improved debugging.
- Allow **fine-tuning** prompts dynamically based on user feedback.

## ğŸ“Œ License
This project is licensed under the MIT License.

---

**ğŸš€ Happy Prompt Engineering!** ğŸ¯
